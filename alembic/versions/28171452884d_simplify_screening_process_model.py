"""simplify_screening_process_model

Revision ID: 28171452884d
Revises: 8588274c0799
Create Date: 2026-01-27 13:54:26.181954

"""

from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = "28171452884d"
down_revision: Union[str, Sequence[str], None] = "8588274c0799"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # === DATA MIGRATION: Copy existing values before renaming columns ===
    # First, add the new columns
    op.add_column(
        "screening_processes", sa.Column("owner_id", sa.Uuid(), nullable=True)
    )
    op.add_column(
        "screening_processes", sa.Column("current_actor_id", sa.Uuid(), nullable=True)
    )

    # Copy data from old columns to new columns
    op.execute("""
        UPDATE screening_processes 
        SET owner_id = assigned_to,
            current_actor_id = current_assignee_id
    """)

    # Update existing screening_status values to valid ones
    # CONVERSATION -> IN_PROGRESS (it's an active state)
    # PENDING_REVIEW -> IN_PROGRESS
    # UNDER_REVIEW -> IN_PROGRESS
    # PENDING_CORRECTION -> IN_PROGRESS
    # ESCALATED -> IN_PROGRESS
    op.execute("""
        UPDATE screening_processes 
        SET status = 'IN_PROGRESS'
        WHERE status IN ('CONVERSATION', 'PENDING_REVIEW', 'UNDER_REVIEW', 'PENDING_CORRECTION', 'ESCALATED')
    """)

    # === INDEX UPDATES ===
    # Drop old indexes
    op.drop_index(
        op.f("ix_screening_processes_assigned_to"), table_name="screening_processes"
    )
    op.drop_index(
        op.f("ix_screening_processes_current_assignee"),
        table_name="screening_processes",
    )
    op.drop_index(
        op.f("ix_screening_processes_escalated_to"), table_name="screening_processes"
    )
    op.drop_index(
        op.f("ix_screening_processes_verifier"), table_name="screening_processes"
    )

    # Create new indexes
    op.create_index(
        "ix_screening_processes_current_actor",
        "screening_processes",
        ["current_actor_id"],
        unique=False,
    )
    op.create_index(
        "ix_screening_processes_owner",
        "screening_processes",
        ["owner_id"],
        unique=False,
    )

    # === DROP OLD COLUMNS ===
    op.drop_column("screening_processes", "reviewed_by")
    op.drop_column("screening_processes", "escalation_reason")
    op.drop_column("screening_processes", "sent_at")
    op.drop_column("screening_processes", "escalated_to")
    op.drop_column("screening_processes", "verifier_id")
    op.drop_column("screening_processes", "submitted_at")
    op.drop_column("screening_processes", "review_notes")
    op.drop_column("screening_processes", "version")
    op.drop_column("screening_processes", "started_at")
    op.drop_column("screening_processes", "client_validation_required")
    op.drop_column("screening_processes", "current_assignee_id")
    op.drop_column("screening_processes", "reviewed_at")
    op.drop_column("screening_processes", "extra_metadata")
    op.drop_column("screening_processes", "assigned_to")

    # === UPDATE ENUM: Remove deprecated values ===
    # PostgreSQL doesn't support removing enum values directly.
    # We need to create a new enum, update the column, and drop the old enum.
    # Since we already migrated data above, we can safely do this.

    # First, drop the partial unique index that references the enum values
    op.execute("DROP INDEX IF EXISTS uq_screening_processes_org_cpf_active")

    # Create new enum type
    op.execute("""
        CREATE TYPE screening_status_new AS ENUM (
            'DRAFT', 'IN_PROGRESS', 'APPROVED', 'REJECTED', 'EXPIRED', 'CANCELLED'
        )
    """)

    # Update column to use new enum type
    op.execute("""
        ALTER TABLE screening_processes 
        ALTER COLUMN status TYPE screening_status_new 
        USING status::text::screening_status_new
    """)

    # Drop old enum and rename new one
    op.execute("DROP TYPE screening_status")
    op.execute("ALTER TYPE screening_status_new RENAME TO screening_status")

    # Recreate the partial unique index with the new enum
    op.execute("""
        CREATE UNIQUE INDEX uq_screening_processes_org_cpf_active 
        ON screening_processes (organization_id, professional_cpf) 
        WHERE status NOT IN ('APPROVED', 'REJECTED', 'EXPIRED', 'CANCELLED') 
        AND deleted_at IS NULL 
        AND professional_cpf IS NOT NULL
    """)

    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###

    # === RESTORE ENUM: Add back deprecated values ===
    # Create old enum type with all values
    op.execute("""
        CREATE TYPE screening_status_old AS ENUM (
            'DRAFT', 'CONVERSATION', 'IN_PROGRESS', 'PENDING_REVIEW', 
            'UNDER_REVIEW', 'PENDING_CORRECTION', 'ESCALATED',
            'APPROVED', 'REJECTED', 'EXPIRED', 'CANCELLED'
        )
    """)

    # Update column to use old enum type
    op.execute("""
        ALTER TABLE screening_processes 
        ALTER COLUMN status TYPE screening_status_old 
        USING status::text::screening_status_old
    """)

    # Drop new enum and rename old one
    op.execute("DROP TYPE screening_status")
    op.execute("ALTER TYPE screening_status_old RENAME TO screening_status")

    # === RESTORE COLUMNS ===
    op.add_column(
        "screening_processes",
        sa.Column("assigned_to", sa.UUID(), autoincrement=False, nullable=True),
    )
    op.add_column(
        "screening_processes",
        sa.Column(
            "extra_metadata",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.add_column(
        "screening_processes",
        sa.Column(
            "reviewed_at",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.add_column(
        "screening_processes",
        sa.Column("current_assignee_id", sa.UUID(), autoincrement=False, nullable=True),
    )
    op.add_column(
        "screening_processes",
        sa.Column(
            "client_validation_required",
            sa.BOOLEAN(),
            server_default=sa.text("false"),
            autoincrement=False,
            nullable=False,
        ),
    )
    op.add_column(
        "screening_processes",
        sa.Column(
            "started_at",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.add_column(
        "screening_processes",
        sa.Column(
            "version",
            sa.INTEGER(),
            server_default=sa.text("1"),
            autoincrement=False,
            nullable=False,
        ),
    )
    op.add_column(
        "screening_processes",
        sa.Column(
            "review_notes", sa.VARCHAR(length=2000), autoincrement=False, nullable=True
        ),
    )
    op.add_column(
        "screening_processes",
        sa.Column(
            "submitted_at",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.add_column(
        "screening_processes",
        sa.Column("verifier_id", sa.UUID(), autoincrement=False, nullable=True),
    )
    op.add_column(
        "screening_processes",
        sa.Column("escalated_to", sa.UUID(), autoincrement=False, nullable=True),
    )
    op.add_column(
        "screening_processes",
        sa.Column(
            "sent_at",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.add_column(
        "screening_processes",
        sa.Column(
            "escalation_reason",
            sa.VARCHAR(length=2000),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.add_column(
        "screening_processes",
        sa.Column("reviewed_by", sa.UUID(), autoincrement=False, nullable=True),
    )

    # === DATA MIGRATION: Copy values back ===
    op.execute("""
        UPDATE screening_processes 
        SET assigned_to = owner_id,
            current_assignee_id = current_actor_id
    """)

    # === INDEX UPDATES ===
    op.drop_index("ix_screening_processes_owner", table_name="screening_processes")
    op.drop_index(
        "ix_screening_processes_current_actor", table_name="screening_processes"
    )
    op.create_index(
        op.f("ix_screening_processes_verifier"),
        "screening_processes",
        ["verifier_id"],
        unique=False,
    )
    op.create_index(
        op.f("ix_screening_processes_escalated_to"),
        "screening_processes",
        ["escalated_to"],
        unique=False,
    )
    op.create_index(
        op.f("ix_screening_processes_current_assignee"),
        "screening_processes",
        ["current_assignee_id"],
        unique=False,
    )
    op.create_index(
        op.f("ix_screening_processes_assigned_to"),
        "screening_processes",
        ["assigned_to"],
        unique=False,
    )

    # === DROP NEW COLUMNS ===
    op.drop_column("screening_processes", "current_actor_id")
    op.drop_column("screening_processes", "owner_id")
    # ### end Alembic commands ###
